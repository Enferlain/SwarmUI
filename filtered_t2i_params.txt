{
    "list": [
        {
            "name": "[Grid Gen] Prompt Replace",
            "id": "gridgenpromptreplace",
            "description": "Replace text in the prompt (or negative prompt) with some other text.",
            "type": "text",
        },
        {
            "name": "[Grid Gen] Presets",
            "id": "gridgenpresets",
            "description": "Apply parameter presets to the image. Can use a comma-separated list to apply multiple per-cell, eg 'a, b || a, c || b, c'"
        },
        {
            "name": "Prompt",
            "id": "prompt",
            "description": "The input prompt text that describes the image you want to generate.\nTell the AI what you want to see.",
            "type": "text",
            "subtype": null,
            "default": "",
            "min": 0.0,
            "max": 0.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 1.0,
            "values": null,
            "value_names": null,
            "examples": [
                "a photo of a cat",
                "a cartoonish drawing of an astronaut"
            ],
            "visible": false,
            "advanced": false,
            "feature_flag": null,
            "toggleable": false,
            "priority": -100.0,
            "group": null,
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "prompt",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Prompt Images",
            "id": "promptimages",
            "description": "Images to include with the prompt, for eg ReVision or UnCLIP.\nIf this parameter is visible, you've done something wrong - this parameter is tracked internally.",
            "type": "image_list",
            "subtype": null,
            "default": "",
            "min": 0.0,
            "max": 0.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 1.0,
            "values": null,
            "value_names": null,
            "examples": null,
            "visible": false,
            "advanced": true,
            "feature_flag": null,
            "toggleable": true,
            "priority": -95.0,
            "group": null,
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "small",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Negative Prompt",
            "id": "negativeprompt",
            "description": "Like the input prompt text, but describe what NOT to generate.\nTell the AI things you don't want to see.",
            "type": "text",
            "subtype": null,
            "default": "",
            "min": 0.0,
            "max": 0.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 1.0,
            "values": null,
            "value_names": null,
            "examples": [
                "ugly, bad, gross",
                "lowres, low quality"
            ],
            "visible": false,
            "advanced": false,
            "feature_flag": null,
            "toggleable": false,
            "priority": -90.0,
            "group": null,
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "prompt",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "ReVision Strength",
            "id": "revisionstrength",
            "description": "How strong to apply ReVision image inputs.\nSet to 0 to disable ReVision processing."
        },
        {
            "name": "ReVision Zero Prompt",
            "id": "revisionzeroprompt",
            "description": "Zeroes the prompt and negative prompt for ReVision inputs.\nApplies only to the base, the refiner will still get prompts.\nIf you want zeros on both, just delete your prompt text.\nIf not checked, empty prompts will be zeroed regardless.",
        },
        {
            "name": "Use Reference Only",
            "id": "usereferenceonly",
            "description": "Use the 'Reference-Only' technique to guide the generation towards the input image.\nThis currently has side effects that notably prevent Batch from being used properly."
        },
        {
            "name": "ReVision Model",
            "id": "revisionmodel",
            "description": "The CLIP Vision model to use for ReVision inputs.\nThis will also override IPAdapter (if IPAdapter-G is in use)."
        },
        {
            "name": "Images",
            "id": "images",
            "description": "How many images to generate at once."
        },
        {
            "name": "Seed",
            "id": "seed",
            "description": "Image seed.\n-1 = random.\nDifferent seeds produce different results for the same prompt.",
            "type": "integer",
            "subtype": null,
            "default": "-1",
            "min": -1.0,
            "max": 9.223372036854776e+18,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 1.0,
            "values": null,
            "value_names": null,
            "examples": [
                "1",
                "2",
                "...",
                "10"
            ],
            "visible": true,
            "advanced": false,
            "feature_flag": null,
            "toggleable": false,
            "priority": -30.0,
            "group": {
                "name": "Core Parameters",
                "id": "coreparameters",
                "toggles": false,
                "open": true,
                "priority": -50.0,
                "description": "",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "seed",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Steps",
            "id": "steps",
            "description": "Diffusion works by running a model repeatedly to slowly build and then refine an image.\nThis parameter is how many times to run the model.\nMore steps = better quality, but more time.\n20 is a good baseline for speed, 40 is good for maximizing quality.\nSome models, such as Turbo models, are intended for low step counts like 4 or 8.\nYou can go much higher, but it quickly becomes pointless above 70 or so.\nNote that steps is a core parameter used for defining diffusion schedules and other advanced internals,\nand merely running the model over top of an existing image is not the same as increasing the steps.\nNote that the number of steps actually ran can be influenced by other parameters such as Init Image Creativity when applied.",
            "type": "integer",
            "subtype": null,
            "default": "20",
            "min": 0.0,
            "max": 500.0,
            "view_min": 0.0,
            "view_max": 100.0,
            "step": 1.0,
            "values": null,
            "value_names": null,
            "examples": [
                "10",
                "15",
                "20",
                "30",
                "40"
            ],
            "visible": true,
            "advanced": false,
            "feature_flag": null,
            "toggleable": false,
            "priority": -20.0,
            "group": {
                "name": "Core Parameters",
                "id": "coreparameters",
                "toggles": false,
                "open": true,
                "priority": -50.0,
                "description": "",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "slider",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "CFG Scale",
            "id": "cfgscale",
            "description": "How strongly to scale prompt input.\nHigher CFG scales tend to produce more contrast, and lower CFG scales produce less contrast.\nToo-high values can cause corrupted/burnt images, too-low can cause nonsensical images.\n7 is a good baseline. Normal usages vary between 4 and 9.\nSome model types, such as Flux or any Turbo model, expect CFG around 1.",
            "type": "decimal",
            "subtype": null,
            "default": "7",
            "min": 0.0,
            "max": 100.0,
            "view_min": 0.0,
            "view_max": 20.0,
            "step": 0.5,
            "values": null,
            "value_names": null,
            "examples": [
                "5",
                "6",
                "7",
                "8",
                "9"
            ],
            "visible": true,
            "advanced": false,
            "feature_flag": null,
            "toggleable": false,
            "priority": -18.0,
            "group": {
                "name": "Core Parameters",
                "id": "coreparameters",
                "toggles": false,
                "open": true,
                "priority": -50.0,
                "description": "",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "slider",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Text2Video Frames",
            "id": "textvideoframes",
            "description": "How many frames to generate within the video.\nGenmo Mochi 1 can support any frame count up to 200, multiples of 6 plus 1 (7, 13, 19, 25, ...) are required and will automatically round if you enter an invalid value. Defaults to 25.\nLTXV supports frame counts anywhere up to 257. Multiples of 8 plus 1 (9, 17, 25, 33, 41, ...) are required and will automatically round if you enter an invalid value. Defaults to 97."
        },
        {
            "name": "Text2Video FPS",
            "id": "textvideofps",
            "description": "The FPS (frames per second) to use for video generation.\nThis configures the target FPS the video is expecting to work at.\nFor Mochi, this is 24.\nFor LTXV, 24 fps is native, but other values may work."
        },
        {
            "name": "Text2Video Boomerang",
            "id": "textvideoboomerang",
            "description": "Whether to boomerang (aka pingpong) the video.\nIf true, the video will play and then play again in reverse to enable smooth looping."
        },
        {
            "name": "Text2Video Format",
            "id": "textvideoformat",
            "description": "What format to save videos in."
        },
        {
            "name": "Variation Seed",
            "id": "variationseed",
            "description": "Image-variation seed.\nCombined partially with the original seed to create a similar-but-different image for the same seed.\n-1 = random."
        },
        {
            "name": "Variation Seed Strength",
            "id": "variationseedstrength",
            "description": "How strongly to apply the variation seed.\n0 = don't use, 1 = replace the base seed entirely. 0.5 is a good value."
        },
        {
            "name": "Aspect Ratio",
            "id": "aspectratio",
            "description": "Image aspect ratio - that is, the shape of the image (wide vs square vs tall).\nSet to 'Custom' to define a manual width/height instead.\nSome models can stretch better than others.\nNotably Flux models support almost any resolution you feel like trying.",
            "type": "dropdown",
            "subtype": null,
            "default": "1:1",
            "min": 0.0,
            "max": 0.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 1.0,
            "values": [
                "1:1",
                "4:3",
                "3:2",
                "8:5",
                "16:9",
                "21:9",
                "3:4",
                "2:3",
                "5:8",
                "9:16",
                "9:21",
                "Custom"
            ],
            "value_names": [
                "1:1 (Square)",
                "4:3 (Old PC)",
                "3:2 (Semi-wide)",
                "8:5",
                "16:9 (Standard Widescreen)",
                "21:9 (Ultra-Widescreen)",
                "3:4",
                "2:3 (Semi-tall)",
                "5:8",
                "9:16 (Tall)",
                "9:21 (Ultra-Tall)",
                "Custom"
            ],
            "examples": null,
            "visible": true,
            "advanced": false,
            "feature_flag": null,
            "toggleable": false,
            "priority": -11.0,
            "group": {
                "name": "Resolution",
                "id": "resolution",
                "toggles": false,
                "open": false,
                "priority": -11.0,
                "description": "",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "small",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Width",
            "id": "width",
            "description": "Image width, in pixels.\nSDv1 uses 512, SDv2 uses 768, SDXL prefers 1024.\nSome models allow variation within a range (eg 512 to 768) but almost always want a multiple of 64.\nFlux is very open to differing values.",
            "type": "integer",
            "subtype": null,
            "default": "512",
            "min": 64.0,
            "max": 16384.0,
            "view_min": 256.0,
            "view_max": 2048.0,
            "step": 32.0,
            "values": null,
            "value_names": null,
            "examples": [
                "512",
                "768",
                "1024"
            ],
            "visible": true,
            "advanced": false,
            "feature_flag": null,
            "toggleable": false,
            "priority": -10.0,
            "group": {
                "name": "Resolution",
                "id": "resolution",
                "toggles": false,
                "open": false,
                "priority": -11.0,
                "description": "",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "pot_slider",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Height",
            "id": "height",
            "description": "Image height, in pixels.\nSDv1 uses 512, SDv2 uses 768, SDXL prefers 1024.\nSome models allow variation within a range (eg 512 to 768) but almost always want a multiple of 64.\nFlux is very open to differing values.",
            "type": "integer",
            "subtype": null,
            "default": "512",
            "min": 64.0,
            "max": 16384.0,
            "view_min": 256.0,
            "view_max": 2048.0,
            "step": 32.0,
            "values": null,
            "value_names": null,
            "examples": [
                "512",
                "768",
                "1024"
            ],
            "visible": true,
            "advanced": false,
            "feature_flag": null,
            "toggleable": false,
            "priority": -9.0,
            "group": {
                "name": "Resolution",
                "id": "resolution",
                "toggles": false,
                "open": false,
                "priority": -11.0,
                "description": "",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "pot_slider",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Cascade Latent Compression",
            "id": "cascadelatentcompression",
            "description": "How deeply to compress latents when using Stable Cascade.\nDefault is 32, you can get slightly faster but lower quality results by using 42."
        },
        {
            "name": "SD3 TextEncs",
            "id": "sdtextencs",
            "description": "Which text encoders to use for Stable Diffusion 3 (SD3) models.\nCan use CLIP pairs, or T5, or both.\nBoth is the standard way to run SD3, but CLIP only uses fewer system resources."
        },
        {
            "name": "Flux Guidance Scale",
            "id": "fluxguidancescale",
            "description": "What guidance scale to use for Flux-Dev models.\nDoes not apply to Flux-Schnell.\nThis is a distilled embedded value the model was trained on, this is based on an alternative guidance methodology, and is not CFG.\n3.5 is default, but closer to 2.0 may allow for more stylistic flexibility."
        },
        {
            "name": "Zero Negative",
            "id": "zeronegative",
            "description": "Zeroes the negative prompt if it's empty.\nDoes nothing if the negative prompt is not empty.\nThis may yield better quality on SD3.",
        },
        {
            "name": "Seamless Tileable",
            "id": "seamlesstileable",
            "description": "Makes the generated image seamlessly tileable (like a 3D texture would be).\nOptionally, can be tileable on only the X axis (horizontal) or Y axis (vertical)."
        },
        {
            "name": "Init Image",
            "id": "initimage",
            "description": "Init-image, to edit an image using diffusion.\nThis process is sometimes called 'img2img' or 'Image To Image'."
        },
        {
            "name": "Init Image Creativity",
            "id": "initimagecreativity",
            "description": "Higher values make the generation more creative, lower values follow the init image closer.\nSometimes referred to as 'Denoising Strength' for 'img2img'.\nIn simple terms: this is the fraction of steps to actually run, vs steps to pretend already ran.\n(Pretending that some steps already ran means the model will act as though it created the image, and only needs to refine the details.\nThis is how init images function on the inside.)\nFor example, at Steps=20 and Creativity=0.6, the model will skip the first 8 steps and run the next 12.\nIf you find your quality is low at low creativity values, it may be beneficial to make your Steps value higher to compensate for this fractional cut.",
        },
        {
            "name": "Init Image Reset To Norm",
            "id": "initimageresettonorm",
            "description": "Merges the init image towards the latent norm.\nThis essentially lets you boost 'init image creativity' past 1.0.\nSet to 0 to disable."
        },
        {
            "name": "Mask Image",
            "id": "maskimage",
            "description": "Mask-image, white pixels are changed, black pixels are not changed, gray pixels are half-changed."
        },
        {
            "name": "Mask Shrink Grow",
            "id": "maskshrinkgrow",
            "description": "If enabled, the image will be shrunk to just the mask, and then grow by this value many pixels.\nAfter that, the generation process will run in full, and the image will be composited back into the original image at the end.\nThis allows for refining small details of an image more effectively.\nThis is also known as 'Inpaint Only Masked'.\nLarger values increase the surrounding context the generation receives, lower values contain it tighter and allow the AI to create more detail."
        },
        {
            "name": "Mask Blur",
            "id": "maskblur",
            "description": "If enabled, the mask will be blurred by this blur factor.\nThis makes the transition for the new image smoother.\nSet to 0 to disable."
        },
        {
            "name": "Mask Grow",
            "id": "maskgrow",
            "description": "If enabled, the mask will be grown by this size (approx equivalent to length in pixels).\nThis helps improve overlap with generated masks.\nSet to 0 to disable."
        },
        {
            "name": "Mask Behavior",
            "id": "maskbehavior",
            "description": "How to process the mask.\n'Differential' = 'Differential Diffusion' technique, wherein the mask values are used as offsets for timestep of when to apply the mask or not.\n'Simple Latent' = the most basic latent masking technique."
        },
        {
            "name": "Init Image Recomposite Mask",
            "id": "initimagerecompositemask",
            "description": "If enabled and a mask is in use, this will recomposite the masked generated onto the original image for a cleaner result.\nIf disabled, VAE artifacts may build up across repeated inpaint operations.\nDefaults enabled."
        },
        {
            "name": "Use Inpainting Encode",
            "id": "useinpaintingencode",
            "description": "Uses VAE Encode logic specifically designed for certain inpainting models.\nNotably this includes the RunwayML Stable-Diffusion-v1 Inpainting model.\nThis covers the masked area with gray."
        },
        {
            "name": "Unsampler Prompt",
            "id": "unsamplerprompt",
            "description": "If enabled, feeds this prompt to an unsampler before resampling with your main prompt.\nThis is powerful for controlled image editing.\n\nFor example, use unsampler prompt 'a photo of a man wearing a black hat',\nand give main prompt 'a photo of a man wearing a sombrero', to change what type of hat a person is wearing.",
        },
        {
            "name": "Refiner Model",
            "id": "refinermodel",
            "description": "The model to use for refinement. This should be a model that's good at small-details, and use a structural model as your base model.\n'Use Base' will use your base model rather than switching.\nSDXL 1.0 released with an official refiner model."
        },
        {
            "name": "Refiner VAE",
            "id": "refinervae",
            "description": "Optional VAE replacement for the refiner stage."
        },
        {
            "name": "Refiner Control Percentage",
            "id": "refinercontrolpercentage",
            "description": "Higher values give the refiner more control, lower values give the base more control.\nThis is similar to 'Init Image Creativity', but for the refiner. This controls how many steps the refiner takes.\nIn simple terms: this is the fraction of total steps to let the refiner run\nFor example, at Steps=20 with ControlPercentage=0.2 and Method=PostApply, the base will run 20 steps, then the refiner will run 20*0.2=just 4 steps.\nIf you find your quality is low at low control percentage values, it may be beneficial to set the advanced Refiner Steps parameter to a very high value let the refine logic run more actual steps.\nFor example, set RefinerSteps=60 so that 60*0.2=12 steps actually ran in the refiner.",
            "type": "decimal",
            "subtype": null,
            "default": "0.2",
            "min": 0.0,
            "max": 1.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 0.05,
            "values": null,
            "value_names": null,
            "examples": [
                "0.2",
                "0.3",
                "0.4"
            ],
            "visible": true,
            "advanced": false,
            "feature_flag": "refiners",
            "toggleable": false,
            "priority": -4.0,
            "group": {
                "name": "Refine / Upscale",
                "id": "refineupscale",
                "toggles": true,
                "open": false,
                "priority": -3.0,
                "description": "This group contains everything related to two-stage image generation.\nNotably this includes post-refinement, step-swap refinement, and upscaled refinement.\nUpscaling an image and refining with the same model has been referred to as 'hires fix' in other UIs.",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": true,
            "view_type": "slider",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Refiner Steps",
            "id": "refinersteps",
            "description": "Alternate Steps value for when calculating the refiner stage.\nThis replaces the 'Steps' total count before calculating the Refiner Control Percentage.\nFor example, with Control=0.2, set RefinerSteps=60 so that 60*0.2=12 steps actually ran in the refiner.",
            "type": "integer",
            "subtype": null,
            "default": "40",
            "min": 1.0,
            "max": 200.0,
            "view_min": 0.0,
            "view_max": 100.0,
            "step": 1.0,
            "values": null,
            "value_names": null,
            "examples": [
                "20",
                "40",
                "60"
            ],
            "visible": true,
            "advanced": true,
            "feature_flag": null,
            "toggleable": true,
            "priority": -3.75,
            "group": {
                "name": "Refine / Upscale",
                "id": "refineupscale",
                "toggles": true,
                "open": false,
                "priority": -3.0,
                "description": "This group contains everything related to two-stage image generation.\nNotably this includes post-refinement, step-swap refinement, and upscaled refinement.\nUpscaling an image and refining with the same model has been referred to as 'hires fix' in other UIs.",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "slider",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Refiner CFG Scale",
            "id": "refinercfgscale",
            "description": "For the refiner model independently of the base model, how strongly to scale prompt input.\nHigher CFG scales tend to produce more contrast, and lower CFG scales produce less contrast.\nToo-high values can cause corrupted/burnt images, too-low can cause nonsensical images.\n7 is a good baseline. Normal usages vary between 4 and 9.\nSome model types, such as Turbo, expect CFG around 1.",
            "type": "decimal",
            "subtype": null,
            "default": "7",
            "min": 0.0,
            "max": 100.0,
            "view_min": 0.0,
            "view_max": 20.0,
            "step": 0.5,
            "values": null,
            "value_names": null,
            "examples": [
                "5",
                "6",
                "7",
                "8",
                "9"
            ],
            "visible": true,
            "advanced": true,
            "feature_flag": null,
            "toggleable": true,
            "priority": -3.5,
            "group": {
                "name": "Refine / Upscale",
                "id": "refineupscale",
                "toggles": true,
                "open": false,
                "priority": -3.0,
                "description": "This group contains everything related to two-stage image generation.\nNotably this includes post-refinement, step-swap refinement, and upscaled refinement.\nUpscaling an image and refining with the same model has been referred to as 'hires fix' in other UIs.",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "slider",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Refiner Method",
            "id": "refinermethod",
            "description": "How to apply the refiner. Different methods create different results.\n'PostApply' runs the base in full, then runs the refiner with an Init Image.\n'StepSwap' swaps the model after x steps during generation.\n'StepSwapNoisy' is StepSwap but with first-stage noise only.",
            "type": "dropdown",
            "subtype": null,
            "default": "PostApply",
            "min": 0.0,
            "max": 0.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 1.0,
            "values": [
                "PostApply",
                "StepSwap",
                "StepSwapNoisy"
            ],
            "value_names": [
                "Post-Apply (Normal)",
                "Step-Swap (SDXL Refiner Model Original)",
                "Step-Swap Noisy (Modified Refiner)"
            ],
            "examples": null,
            "visible": true,
            "advanced": true,
            "feature_flag": "refiners",
            "toggleable": false,
            "priority": -3.0,
            "group": {
                "name": "Refine / Upscale",
                "id": "refineupscale",
                "toggles": true,
                "open": false,
                "priority": -3.0,
                "description": "This group contains everything related to two-stage image generation.\nNotably this includes post-refinement, step-swap refinement, and upscaled refinement.\nUpscaling an image and refining with the same model has been referred to as 'hires fix' in other UIs.",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": true,
            "view_type": "small",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Refiner Upscale",
            "id": "refinerupscale",
            "description": "Optional upscale of the image between the base and refiner stage.\nSometimes referred to as 'high-res fix'.\nSetting to '1' disables the upscale."
        },
        {
            "name": "Refiner Do Tiling",
            "id": "refinerdotiling",
            "description": "If enabled, do generation tiling in the refiner stage.\nThis can fix some visual artifacts from scaling, but also introduce others (eg seams).\nThis may take a while to run.\nRecommended for SD3 if upscaling."
        },
        {
            "name": "ControlNet Image Input",
            "id": "controlnetimageinput",
            "description": "The image to use as the input to ControlNet guidance.\nThis image will be preprocessed by the chosen preprocessor.\nIf ControlNet is enabled, but this input is not, Init Image will be used instead."
        },
        {
            "name": "ControlNet Model",
            "id": "controlnetmodel",
            "description": "The ControlNet model to use."
        },
        {
            "name": "ControlNet Strength",
            "id": "controlnetstrength",
            "description": "Higher values make the ControlNet apply more strongly. Weaker values let the prompt overrule the ControlNet.",
        },
        {
            "name": "ControlNet Start",
            "id": "controlnetstart",
            "description": "When to start applying controlnet, as a fraction of steps.\nFor example, 0.5 starts applying halfway through. Must be less than End.\nExcluding early steps reduces the controlnet's impact on overall image structure.",
        },
        {
            "name": "ControlNet End",
            "id": "controlnetend",
            "description": "When to stop applying controlnet, as a fraction of steps.\nFor example, 0.5 stops applying halfway through. Must be greater than Start.\nExcluding later steps reduces the controlnet's impact on finer details.",
        },
        {
            "name": "ControlNet Two Image Input",
            "id": "controlnettwoimageinput",
            "description": "The image to use as the input to ControlNet guidance.\nThis image will be preprocessed by the chosen preprocessor.\nIf ControlNet is enabled, but this input is not, Init Image will be used instead."
        },
        {
            "name": "ControlNet Two Model",
            "id": "controlnettwomodel",
            "description": "The ControlNet model to use."
        },
        {
            "name": "ControlNet Two Strength",
            "id": "controlnettwostrength",
            "description": "Higher values make the ControlNet apply more strongly. Weaker values let the prompt overrule the ControlNet.",
        },
        {
            "name": "ControlNet Two Start",
            "id": "controlnettwostart",
            "description": "When to start applying controlnet, as a fraction of steps.\nFor example, 0.5 starts applying halfway through. Must be less than End.\nExcluding early steps reduces the controlnet's impact on overall image structure.",

        },
        {
            "name": "ControlNet Two End",
            "id": "controlnettwoend",
            "description": "When to stop applying controlnet, as a fraction of steps.\nFor example, 0.5 stops applying halfway through. Must be greater than Start.\nExcluding later steps reduces the controlnet's impact on finer details.",
        },
        {
            "name": "ControlNet Three Image Input",
            "id": "controlnetthreeimageinput",
            "description": "The image to use as the input to ControlNet guidance.\nThis image will be preprocessed by the chosen preprocessor.\nIf ControlNet is enabled, but this input is not, Init Image will be used instead."
        },
        {
            "name": "ControlNet Three Model",
            "id": "controlnetthreemodel",
            "description": "The ControlNet model to use."
        },
        {
            "name": "ControlNet Three Strength",
            "id": "controlnetthreestrength",
            "description": "Higher values make the ControlNet apply more strongly. Weaker values let the prompt overrule the ControlNet.",
        },
        {
            "name": "ControlNet Three Start",
            "id": "controlnetthreestart",
            "description": "When to start applying controlnet, as a fraction of steps.\nFor example, 0.5 starts applying halfway through. Must be less than End.\nExcluding early steps reduces the controlnet's impact on overall image structure.",
        },
        {
            "name": "ControlNet Three End",
            "id": "controlnetthreeend",
            "description": "When to stop applying controlnet, as a fraction of steps.\nFor example, 0.5 stops applying halfway through. Must be greater than Start.\nExcluding later steps reduces the controlnet's impact on finer details.",
        },
        {
            "name": "ControlNet Preview Only",
            "id": "controlnetpreviewonly",
            "description": "(For API usage) If enabled, requests preview output from ControlNet and no image generation at all."
        },
        {
            "name": "Video Model",
            "id": "videomodel",
            "description": "The model to use for video generation.\nThis should be an SVD (Stable Video Diffusion) model.\nNote that SVD favors a low CFG (~2.5).\nLTXV prefers a CFG around 3."
        },
        {
            "name": "Video Frames",
            "id": "videoframes",
            "description": "How many frames to generate within the video.\nSVD-XT prefers 25.\nLTXV supports frame counts anywhere up to 257. Multiples of 8 plus 1 (9, 17, 25, 33, 41, ...) are required and will automatically round if you enter an invalid value. Defaults to 97."
        },
        {
            "name": "Video FPS",
            "id": "videofps",
            "description": "The FPS (frames per second) to use for video generation.\nThis configures the target FPS the video will try to generate for.\nLTXV prefers 24."
        },
        {
            "name": "Video Steps",
            "id": "videosteps",
            "description": "How many steps to use for the video model.\nHigher step counts yield better quality, but much longer generation time.\n40 will get good quality, but 20 is sufficient as a basis.",
        },
        {
            "name": "Video CFG",
            "id": "videocfg",
            "description": "The CFG Scale to use for video generation.\nVideos start with this CFG on the first frame, and then reduce to MinCFG (normally 1) by the end frame.\nSVD-XT normally uses 25 frames, and SVD (non-XT) 0.9 used 14 frames.\nLTXV prefers around 3 for its CFG."
        },
        {
            "name": "Video Min CFG",
            "id": "videomincfg",
            "description": "The minimum CFG to use for video generation.\nVideos start with max CFG on first frame, and then reduce to this CFG. Set to -1 to disable.\nOnly used for SVD."
        },
        {
            "name": "Video Motion Bucket",
            "id": "videomotionbucket",
            "description": "Which trained 'motion bucket' to use for the video model.\nHigher values induce more motion. Most values should stay in the 100-200 range.\n127 is a good baseline, as it is the most common value in SVD's training set."
        },
        {
            "name": "Video Augmentation Level",
            "id": "videoaugmentationlevel",
            "description": "How much noise to add to the init image.\nHigher values yield more motion.\nFor SVD, default is 0.\nFor LTX, default is 0.15."
        },
        {
            "name": "Video Boomerang",
            "id": "videoboomerang",
            "description": "Whether to boomerang (aka pingpong) the video.\nIf true, the video will play and then play again in reverse to enable smooth looping."
        },
        {
            "name": "Video Resolution",
            "id": "videoresolution",
            "description": "What resolution/aspect the video should use.\n'Image Aspect, Model Res' uses the aspect-ratio of the image, but the pixel-count size of the model standard resolution.\n'Model Preferred' means use the model's exact resolution (eg 1024x576).\n'Image' means your input image resolution."
        },
        {
            "name": "Video Format",
            "id": "videoformat",
            "description": "What format to save videos in."
        },
        {
            "name": "Model",
            "id": "model",
            "description": "What main checkpoint model should be used."
        },
        {
            "name": "VAE",
            "id": "vae",
            "description": "The VAE (Variational Auto-Encoder) controls the translation between images and latent space.\nIf your images look faded out, or glitched, you may have the wrong VAE.\nAll models have a VAE baked in by default, this option lets you swap to a different one if you want to."
        },
        {
            "name": "Automatic VAE",
            "id": "automaticvae",
            "description": "Whether to automatically select the VAE based on the main model and your user settings.\nOnly applied if a VAE is not specified."
        },
        {
            "name": "LoRAs",
            "id": "loras",
            "description": "LoRAs (Low-Rank-Adaptation Models) are a way to customize the content of a model without totally replacing it.\nYou can enable one or several LoRAs over top of one model."
        },
        {
            "name": "LoRA Weights",
            "id": "loraweights",
            "description": "Weight values for the LoRA model list.\nComma separated list of weight numbers.\nMust match the length of the LoRAs input."
        },
        {
            "name": "LoRA Section Confinement",
            "id": "lorasectionconfinement",
            "description": "Optional internal parameter used to confine LoRAs to certain sections of generation (eg a 'segment' block).\nComma separated list of section IDs (0 to mean global).\nMust match the length of the LoRAs input."
        },
        {
            "name": "Batch Size",
            "id": "batchsize",
            "description": "Batch size - generates more images at once on a single GPU.\nThis increases VRAM usage.\nMay in some cases increase overall speed by a small amount (runs slower to get the images, but slightly faster per-image).",
            "type": "integer",
            "subtype": null,
            "default": "1",
            "min": 1.0,
            "max": 100.0,
            "view_min": 0.0,
            "view_max": 10.0,
            "step": 1.0,
            "values": null,
            "value_names": null,
            "examples": null,
            "visible": true,
            "advanced": true,
            "feature_flag": null,
            "toggleable": false,
            "priority": -20.0,
            "group": {
                "name": "Swarm Internal",
                "id": "swarminternal",
                "toggles": false,
                "open": false,
                "priority": 0.0,
                "description": "",
                "advanced": true,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "slider",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Alt Resolution Height Multiplier",
            "id": "altresolutionheightmultiplier",
            "description": "When enabled, the normal width parameter is used, and this value is multiplied by the width to derive the image height.",
        },
        {
            "name": "Save Intermediate Images",
            "id": "saveintermediateimages",
            "description": "If checked, intermediate images (eg before a refiner or segment stage) will be saved separately alongside the final image."
        },
        {
            "name": "Do Not Save",
            "id": "donotsave",
            "description": "If checked, tells the server to not save this image.\nUseful for quick test generations, or 'generate forever' usage."
        },
        {
            "name": "No Previews",
            "id": "nopreviews",
            "description": "If checked, tells the server that previews are not desired.\nMay make generations slightly faster in some cases."
        },
        {
            "name": "Webhooks",
            "id": "webhooks",
            "description": "What webhooks are enabled for this generation job."
        },
        {
            "name": "[Internal] Backend Type",
            "id": "internalbackendtype",
            "description": "Which SwarmUI backend type should be used for this request."
        },
        {
            "name": "Exact Backend ID",
            "id": "exactbackendid",
            "description": "Manually force a specific exact backend (by ID #) to be used for this generation."
        },
        {
            "name": "Wildcard Seed",
            "id": "wildcardseed",
            "description": "Wildcard selection seed.\nIf enabled, this seed will be used for selecting entries from wildcards.\nIf disabled, the image seed will be used.\n-1 = random."
        },
        {
            "name": "No Seed Increment",
            "id": "noseedincrement",
            "description": "If checked, the seed will not be incremented when Images is above 1.\nUseful for example to test different wildcards for the same seed rapidly."
        },
        {
            "name": "Raw Resolution",
            "id": "rawresolution",
            "description": "Optional advanced way to manually specify raw resolutions, useful for grids.\nWhen enabled, this overrides the default width/height params.",
            "type": "text",
            "subtype": null,
            "default": "1024x1024",
            "min": 0.0,
            "max": 0.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 1.0,
            "values": null,
            "value_names": null,
            "examples": [
                "512x512",
                "1024x1024",
                "1344x768"
            ],
            "visible": true,
            "advanced": true,
            "feature_flag": null,
            "toggleable": true,
            "priority": -3.0,
            "group": {
                "name": "Swarm Internal",
                "id": "swarminternal",
                "toggles": false,
                "open": false,
                "priority": 0.0,
                "description": "",
                "advanced": true,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "small",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Personal Note",
            "id": "personalnote",
            "description": "Optional field to type in any personal text note you want.\nThis will be stored in the image metadata."
        },
        {
            "name": "Image Format",
            "id": "imageformat",
            "description": "Optional override for the final image file format."
        },
        {
            "name": "Color Depth",
            "id": "colordepth",
            "description": "Specifies the color depth (in bits per channel) to use.\nOnly works for 'PNG' image file format currently.\n'8-bit' is normal (8 bits per red, 8 for green, 8 for blue, making 24 bits total per pixel).\nand '16-bit' encodes additional high-precision (HDR-like) data.\nNote that overprecision data is unlikely to be meaningful, as currently available models haven't been trained for that."
        },
        {
            "name": "Model Specific Enhancements",
            "id": "modelspecificenhancements",
            "description": "If checked, enables model-specific enhancements.\nFor example, on SDXL, smarter res-cond will be used.\nIf unchecked, will prefer more 'raw' behavior."
        },
        {
            "name": "[FreeU] Apply To",
            "id": "freeuapplyto",
            "description": "Which models to apply FreeU to, as base, refiner, or both. Irrelevant when not using refiner."
        },
        {
            "name": "[FreeU] Version",
            "id": "freeuversion",
            "description": "Which version of FreeU to use.\n1 is the version in the original paper, 2 is a variation of it developed by the same original author of FreeU."
        },
        {
            "name": "[FreeU] Block One",
            "id": "freeublockone",
            "description": "Block1 multiplier value for FreeU.\nPaper recommends 1.1."
        },
        {
            "name": "[FreeU] Block Two",
            "id": "freeublocktwo",
            "description": "Block2 multiplier value for FreeU.\nPaper recommends 1.2."
        },
        {
            "name": "[FreeU] Skip One",
            "id": "freeuskipone",
            "description": "Skip1 multiplier value for FreeU.\nPaper recommends 0.9."
        },
        {
            "name": "[FreeU] Skip Two",
            "id": "freeuskiptwo",
            "description": "Skip2 multiplier value for FreeU.\nPaper recommends 0.2."
        },
        {
            "name": "Global Region Factor",
            "id": "globalregionfactor",
            "description": "When using regionalized prompts, this factor controls how strongly the global prompt overrides the regional prompts.\n0 means ignore global prompt, 1 means ignore regional, 0.5 means half-n-half.",
        },
        {
            "name": "Regional Object Cleanup Factor",
            "id": "regionalobjectcleanupfactor",
            "description": "When using an 'object' prompt, how much to cleanup the end result by.\nThis is the 'init image creativity' of the final cleanup step.\nSet to 0 to disable.",
        },
        {
            "name": "Regional Object Inpainting Model",
            "id": "regionalobjectinpaintingmodel",
            "description": "When using regionalized prompts with distinct 'object' values, this overrides the model used to inpaint those objects.",
        },
        {
            "name": "Segment Model",
            "id": "segmentmodel",
            "description": "Optionally specify a distinct model to use for 'segment' values."
        },
        {
            "name": "Mask Composite Unthresholded",
            "id": "maskcompositeunthresholded",
            "description": "If checked, when masks are recomposited (eg from a '<segment:>'), it will be recomposited with the exact raw mask.\nIf false, it will boolean threshold the mask first.\nThe boolean threshold is 'more correct' and leads to better content replacement, whereas disabling threshold (by checking this option) may lead to better looking refinements."
        },
        {
            "name": "Save Segment Mask",
            "id": "savesegmentmask",
            "description": "If checked, any usage of '<segment:>' syntax in prompts will save the generated mask in output.",
        },
        {
            "name": "Segment Mask Blur",
            "id": "segmentmaskblur",
            "description": "Amount of blur to apply to the segment mask before using it.\nThis is for '<segment:>' syntax usage.\nDefaults to 10."
        },
        {
            "name": "Segment Mask Grow",
            "id": "segmentmaskgrow",
            "description": "Number of pixels of grow the segment mask by.\nThis is for '<segment:>' syntax usage.\nDefaults to 16."
        },
        {
            "name": "Segment Mask Oversize",
            "id": "segmentmaskoversize",
            "description": "How wide a segment mask should be oversized by.\nLarger values include more context to get more accurate inpaint,\nand smaller values get closer to get better details."
        },
        {
            "name": "Segment Threshold Max",
            "id": "segmentthresholdmax",
            "description": "Maximum mask match value of a segment before clamping.\nLower values force more of the mask to be counted as maximum masking.\nToo-low values may include unwanted areas of the image.\nHigher values may soften the mask."
        },
        {
            "name": "End Steps Early",
            "id": "endstepsearly",
            "description": "Percentage of steps to cut off before the image is done generation.",
        },
        {
            "name": "Sampler Sigma Min",
            "id": "samplersigmamin",
            "description": "Minimum sigma value for the sampler.\nOnly applies to Karras/Exponential schedulers.",
        },
        {
            "name": "Sampler Sigma Max",
            "id": "samplersigmamax",
            "description": "Maximum sigma value for the sampler.\nOnly applies to Karras/Exponential schedulers.",
            "type": "decimal",
            "subtype": null,
            "default": "10",
            "min": 0.0,
            "max": 1000.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 0.01,
            "values": null,
            "value_names": null,
            "examples": null,
            "visible": true,
            "advanced": true,
            "feature_flag": "sd3",
            "toggleable": true,
            "priority": -22.0,
            "group": {
                "name": "Advanced Sampling",
                "id": "advancedsampling",
                "toggles": false,
                "open": false,
                "priority": 10.0,
                "description": "",
                "advanced": true,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "small",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Sigma Shift",
            "id": "sigmashift",
            "description": "Sigma shift is used for MMDiT models (like SD3) specifically.\nFor SD3, this value is recommended to be in the range of 1.5 to 3, normally 3.\nFor AuraFlow, 1.73 (square root of 3) is recommended.\nFor Flux, Schnell uses 0, 1.15 may be good for Dev."
        },
        {
            "name": "Sampler Rho",
            "id": "samplerrho",
            "description": "Rho value for the sampler.\nOnly applies to Karras/Exponential schedulers.",
            "type": "decimal",
            "subtype": null,
            "default": "7",
            "min": 0.0,
            "max": 1000.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 0.01,
            "values": null,
            "value_names": null,
            "examples": null,
            "visible": true,
            "advanced": true,
            "feature_flag": null,
            "toggleable": true,
            "priority": -20.0,
            "group": {
                "name": "Advanced Sampling",
                "id": "advancedsampling",
                "toggles": false,
                "open": false,
                "priority": 10.0,
                "description": "",
                "advanced": true,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "small",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "IP2P CFG 2",
            "id": "ippcfg",
            "description": "CFG Scale for Cond2-Negative in InstructPix2Pix (Edit) models."
        },
        {
            "name": "CLIP Stop At Layer",
            "id": "clipstopatlayer",
            "description": "What layer of CLIP to stop at, from the end.\nAlso known as 'CLIP Skip'. Default CLIP Skip is -1 for SDv1, some models prefer -2.\nSDv2, SDXL, and beyond do not need this set ever."
        },
        {
            "name": "VAE Tile Size",
            "id": "vaetilesize",
            "description": "If enabled, decodes images through the VAE using tiles of this size.\nVAE Tiling reduces VRAM consumption, but takes longer and may impact quality."
        },
        {
            "name": "VAE Tile Overlap",
            "id": "vaetileoverlap",
            "description": "If VAE Tile Size is enabled, this controls how much overlap between tiles there should be.\nHigher overlap improves quality but takes longer."
        },
        {
            "name": "Remove Background",
            "id": "removebackground",
            "description": "If enabled, removes the background from the generated image.\nThis internally uses RemBG."
        },
        {
            "name": "Automatic Scorer",
            "id": "automaticscorer",
            "description": "Scoring engine(s) to use when scoring this image. Multiple scorers can be used and will be averaged together. Scores are saved in image metadata."
        },
        {
            "name": "Score Must Exceed",
            "id": "scoremustexceed",
            "description": "Only keep images with a generated score above this minimum."
        },
        {
            "name": "Take Best N Score",
            "id": "takebestnscore",
            "description": "Only keep the best *this many* images in a batch based on scoring.\n(For example, if batch size = 8, and this value = 2, then 8 images will generate and will be scored, and the 2 best will be kept and the other 6 discarded.)",
            "type": "integer",
            "subtype": null,
            "default": "1",
            "min": 1.0,
            "max": 100.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 1.0,
            "values": null,
            "value_names": null,
            "examples": [
                "1",
                "2",
                "3"
            ],
            "visible": true,
            "advanced": false,
            "feature_flag": null,
            "toggleable": true,
            "priority": 10.0,
            "group": {
                "name": "Scoring",
                "id": "scoring",
                "toggles": true,
                "open": false,
                "priority": 10.0,
                "description": "The Scorers extension implements automatic image scoring, useful for eg Grid Generator usage to automatically rate the grid.\nThis is a legacy implementation pending a rewrite. Most users should not use this.",
                "advanced": true,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "small",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "[DT] Mimic Scale",
            "id": "dtmimicscale",
            "description": "[Dynamic Thresholding]\nMimic Scale value (target for the CFG Scale recentering)."
        },
        {
            "name": "[DT] Threshold Percentile",
            "id": "dtthresholdpercentile",
            "description": "[Dynamic Thresholding]\nthresholding percentile. '1' disables, '0.95' is decent value for enabled."
        },
        {
            "name": "[DT] CFG Scale Mode",
            "id": "dtcfgscalemode",
            "description": "[Dynamic Thresholding]\nMode for the CFG Scale scheduler.",
        },
        {
            "name": "[DT] CFG Scale Minimum",
            "id": "dtcfgscaleminimum",
            "description": "[Dynamic Thresholding]\nCFG Scale minimum value (for non-constant CFG mode)."
        },
        {
            "name": "[DT] Mimic Scale Mode",
            "id": "dtmimicscalemode",
            "description": "[Dynamic Thresholding]\nMode for the Mimic Scale scheduler.",
        },
        {
            "name": "[DT] Mimic Scale Minimum",
            "id": "dtmimicscaleminimum",
            "description": "[Dynamic Thresholding]\nMimic Scale minimum value (for non-constant mimic mode)."
        },
        {
            "name": "[DT] Scheduler Value",
            "id": "dtschedulervalue",
            "description": "[Dynamic Thresholding]\nIf either scale scheduler is 'Power', this is the power factor.\nIf using 'repeating', this is the number of repeats per image. Otherwise, it does nothing.",
        },
        {
            "name": "[DT] Separate Feature Channels",
            "id": "dtseparatefeaturechannels",
            "description": "[Dynamic Thresholding]\nWhether to separate the feature channels.\nNormally leave this on. I think it should be off for RCFG?"
        },
        {
            "name": "[DT] Scaling Startpoint",
            "id": "dtscalingstartpoint",
            "description": "[Dynamic Thresholding]\nWhether to scale relative to the mean value or to zero.\nUse 'MEAN' normally. If you want RCFG logic, use 'ZERO'."
        },
        {
            "name": "[DT] Variability Measure",
            "id": "dtvariabilitymeasure",
            "description": "[Dynamic Thresholding]\nWhether to use standard deviation ('STD') or thresholded absolute values ('AD').\nNormally use 'AD'. Use 'STD' if wanting RCFG logic."
        },
        {
            "name": "[DT] Interpolate Phi",
            "id": "dtinterpolatephi",
            "description": "[Dynamic Thresholding]\n'phi' interpolation factor.\nInterpolates between original value and DT value, such that 0.0 = use original, and 1.0 = use DT.\n(This exists because RCFG is bad and so half-removing it un-breaks it - better to just not do RCFG)."
        },
        {
            "name": "Use IP-Adapter",
            "id": "useipadapter",
            "description": "Select an IP-Adapter model to use IP-Adapter for image-prompt input handling.\nModels will automatically be downloaded when you first use them.\nNote if you use a custom model, you must also set your ReVision Model under Advanced Model Addons, otherwise CLIP Vision G will be presumed.\n<a target=\"_blank\" href=\"https://github.com/mcmonkeyprojects/SwarmUI/blob/master/docs//Features/ImagePrompting.md\">See more docs here.</a>",
        },
        {
            "name": "IP-Adapter Weight",
            "id": "ipadapterweight",
            "description": "Weight to use with IP-Adapter (if enabled)."
        },
        {
            "name": "IP-Adapter Start",
            "id": "ipadapterstart",
            "description": "When to start applying IP-Adapter, as a fraction of steps (if enabled).\nFor example, 0.25 starts applying a quarter (25%) of the way through. Must be less than IP-Adapter End.",
        },
        {
            "name": "IP-Adapter End",
            "id": "ipadapterend",
            "description": "When to stop applying IP-Adapter, as a fraction of steps (if enabled).\nFor example, 0.5 stops applying halfway (50%) through. Must be greater than IP-Adapter Start.",
        },
        {
            "name": "IP-Adapter Weight Type",
            "id": "ipadapterweighttype",
            "description": "How to shift the weighting of the IP-Adapter.\nThis can produce subtle but useful different effects."
        },
        {
            "name": "Use Style Model",
            "id": "usestylemodel",
            "description": "Select a Style model to use it for image-prompt input handling.\nFlux.1 Redux is an example of a style model.\nPlace these models in `(Swarm)/Models/style_models`.",
        },
        {
            "name": "Style Model Merge Strength",
            "id": "stylemodelmergestrength",
            "description": "How strongly to merge in the effects of the style model.\nAt 1, the style model is fully used.\nAt 0, the style model is ignored.\nFor Flux Redux, very low values (eg 0.1) are recommended."
        },
        {
            "name": "Style Model Multiply Strength",
            "id": "stylemodelmultiplystrength",
            "description": "How strongly to multiply the effects of the style model.\nAt 1, the style model is fully used.\nAt 0, the style model is ignored.\nFor Flux Redux, very low values (eg 0.1) are recommended."
        },
        {
            "name": "Style Model Apply Start",
            "id": "stylemodelapplystart",
            "description": "When to start applying the Style Model, as a fraction of steps (if enabled).\nFor example, 0.25 starts applying a quarter (25%) of the way through.\nThis is probably off-scale due to scheduler behavior in ComfyUI internals. Very low values are recommend for practical usage.",
        },
        {
            "name": "[ComfyUI] Custom Workflow",
            "id": "comfyuicustomworkflow",
            "description": "What custom workflow to use in ComfyUI (built in the Comfy Workflow Editor tab).\nGenerally, do not use this directly."
        },
        {
            "name": "Sampler",
            "id": "sampler",
            "description": "Sampler type (for ComfyUI backends).\nGenerally, 'Euler' is fine, but for SD1 and SDXL 'DPM++ 2M' is popular when paired with the 'Karras' scheduler.\n'Ancestral' and 'SDE' samplers only work with non-rectified models (eg SD1/SDXL) and randomly move over time.",
            "type": "dropdown",
            "subtype": null,
            "default": "euler",
            "min": 0.0,
            "max": 0.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 1.0,
            "values": [
                "euler",
                "euler_ancestral",
                "heun",
                "heunpp2",
                "dpm_2",
                "dpm_2_ancestral",
                "lms",
                "dpm_fast",
                "dpm_adaptive",
                "dpmpp_2s_ancestral",
                "dpmpp_sde",
                "dpmpp_sde_gpu",
                "dpmpp_2m",
                "dpmpp_2m_sde",
                "dpmpp_2m_sde_gpu",
                "dpmpp_3m_sde",
                "dpmpp_3m_sde_gpu",
                "ddim",
                "ddpm",
                "lcm",
                "uni_pc",
                "uni_pc_bh2",
                "euler_cfg_pp",
                "euler_ancestral_cfg_pp",
                "dpmpp_2m_cfg_pp",
                "dpmpp_2s_ancestral_cfg_pp",
                "ipndm",
                "ipndm_v",
                "deis"
            ],
            "value_names": [
                "Euler",
                "Euler Ancestral (Randomizing)",
                "Heun",
                "Heun++ 2",
                "DPM-2 (Diffusion Probabilistic Model)",
                "DPM-2 Ancestral",
                "LMS (Linear Multi-Step)",
                "DPM Fast (DPM without the DPM2 slowdown)",
                "DPM Adaptive (Dynamic Steps)",
                "DPM++ 2S Ancestral (2nd Order Single-Step)",
                "DPM++ SDE (Stochastic / randomizing)",
                "DPM++ SDE, GPU Seeded",
                "DPM++ 2M (2nd Order Multi-Step)",
                "DPM++ 2M SDE",
                "DPM++ 2M SDE, GPU Seeded",
                "DPM++ 3M SDE (3rd Order Multi-Step)",
                "DPM++ 3M SDE, GPU Seeded",
                "DDIM (Denoising Diffusion Implicit Models)",
                "DDPM (Denoising Diffusion Probabilistic Models)",
                "LCM (for LCM models)",
                "UniPC (Unified Predictor-Corrector)",
                "UniPC BH2",
                "Euler CFG++ (Manifold-constrained CFG)",
                "Euler Ancestral CFG++",
                "DPM++ 2M CFG++",
                "DPM++ 2S Ancestral CFG++",
                "iPNDM (Improved Pseudo-Numerical methods for Diffusion Models)",
                "iPNDM-V (Variable-Step)",
                "DEIS (Diffusion Exponential Integrator Sampler)"
            ],
            "examples": null,
            "visible": true,
            "advanced": false,
            "feature_flag": "comfyui",
            "toggleable": true,
            "priority": -5.0,
            "group": {
                "name": "Sampling",
                "id": "sampling",
                "toggles": false,
                "open": false,
                "priority": -8.0,
                "description": "",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "small",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Scheduler",
            "id": "scheduler",
            "description": "Scheduler type (for ComfyUI backends).\nGoes with the Sampler parameter above.",
            "type": "dropdown",
            "subtype": null,
            "default": "normal",
            "min": 0.0,
            "max": 0.0,
            "view_min": 0.0,
            "view_max": 0.0,
            "step": 1.0,
            "values": [
                "normal",
                "karras",
                "exponential",
                "simple",
                "ddim_uniform",
                "sgm_uniform",
                "turbo",
                "align_your_steps",
                "beta",
                "linear_quadratic",
                "ltxv",
                "ltxv-image"
            ],
            "value_names": [
                "Normal",
                "Karras",
                "Exponential",
                "Simple",
                "DDIM Uniform",
                "SGM Uniform",
                "Turbo (for turbo models)",
                "Align Your Steps (NVIDIA)",
                "Beta",
                "Linear Quadratic (Mochi)",
                "LTX-Video",
                "ltxv-image (New)"
            ],
            "examples": null,
            "visible": true,
            "advanced": false,
            "feature_flag": "comfyui",
            "toggleable": true,
            "priority": -4.0,
            "group": {
                "name": "Sampling",
                "id": "sampling",
                "toggles": false,
                "open": false,
                "priority": -8.0,
                "description": "",
                "advanced": false,
                "can_shrink": true
            },
            "always_retain": false,
            "do_not_save": false,
            "do_not_preview": false,
            "view_type": "small",
            "extra_hidden": false,
            "nonreusable": false
        },
        {
            "name": "Enable AITemplate",
            "id": "enableaitemplate",
            "description": "If checked, enables AITemplate for ComfyUI generations (UNet only). Only compatible with some GPUs."
        },
        {
            "name": "Preferred DType",
            "id": "preferreddtype",
            "description": "Preferred data type for models, when a choice is available.\n(Notably primarily affects Flux.1 models currently).\nIf disabled, will automatically decide.\n'fp8_e43fn' is recommended for large models.\n'Default' uses global default type, usually fp16 or bf16."
        },
        {
            "name": "Self-Attention Guidance Scale",
            "id": "selfattentionguidancescale",
            "description": "Scale for Self-Attention Guidance.\n''Self-Attention Guidance (SAG) uses the intermediate self-attention maps of diffusion models to enhance their stability and efficacy.\nSpecifically, SAG adversarially blurs only the regions that diffusion models attend to at each iteration and guides them accordingly.''\nDefaults to 0.5."
        },
        {
            "name": "Self-Attention Guidance Sigma Blur",
            "id": "selfattentionguidancesigmablur",
            "description": "Blur-sigma for Self-Attention Guidance.\nDefaults to 2.0."
        },
        {
            "name": "Perturbed-Attention Guidance Scale",
            "id": "perturbedattentionguidancescale",
            "description": "Scale for Perturbed-Attention Guidance (PAG).\n''PAG is designed to progressively enhance the structure of synthesized samples throughout the denoising process by considering the self-attention mechanisms' ability to capture structural information.\nIt involves generating intermediate samples with degraded structure by substituting selected self-attention maps in diffusion U-Net with an identity matrix, and guiding the denoising process away from these degraded samples.''\nDefaults to 3."
        },
        {
            "name": "Refiner Upscale Method",
            "id": "refinerupscalemethod",
            "description": "How to upscale the image, if upscaling is used."
        },
        {
            "name": "ControlNet Preprocessor",
            "id": "controlnetpreprocessor",
            "description": "The preprocessor to use on the ControlNet input image.\nIf toggled off, will be automatically selected.\nUse 'None' to disable preprocessing."
        },
        {
            "name": "ControlNet Union Type",
            "id": "controlnetuniontype",
            "description": "For Union ControlNets, you can optionally manually specify the union controlnet type."
        },
        {
            "name": "ControlNet Two Preprocessor",
            "id": "controlnettwopreprocessor",
            "description": "The preprocessor to use on the ControlNet input image.\nIf toggled off, will be automatically selected.\nUse 'None' to disable preprocessing."
        },
        {
            "name": "ControlNet Two Union Type",
            "id": "controlnettwouniontype",
            "description": "For Union ControlNets, you can optionally manually specify the union controlnet type."
        },
        {
            "name": "ControlNet Three Preprocessor",
            "id": "controlnetthreepreprocessor",
            "description": "The preprocessor to use on the ControlNet input image.\nIf toggled off, will be automatically selected.\nUse 'None' to disable preprocessing."
        },
        {
            "name": "ControlNet Three Union Type",
            "id": "controlnetthreeuniontype",
            "description": "For Union ControlNets, you can optionally manually specify the union controlnet type."
        },
        {
            "name": "Debug Regional Prompting",
            "id": "debugregionalprompting",
            "description": "If checked, outputs masks from regional prompting for debug reasons.",
        },
        {
            "name": "Refiner HyperTile",
            "id": "refinerhypertile",
            "description": "The size of hypertiles to use for the refining stage.\nHyperTile is a technique to speed up sampling of large images by tiling the image and batching the tiles.\nThis is useful when using SDv1 models as the refiner. SDXL-Base models do not benefit as much."
        },
        {
            "name": "Text2Video Preview Type",
            "id": "textvideopreviewtype",
            "description": "How to display previews for generating videos.\n'Animate' shows a low-res animated video preview.\n'iterate' shows one frame at a time while it goes.\n'one' displays just the first frame.\n'none' disables previews."
        },
        {
            "name": "Video Preview Type",
            "id": "videopreviewtype",
            "description": "How to display previews for generating videos.\n'Animate' shows a low-res animated video preview.\n'iterate' shows one frame at a time while it goes.\n'one' displays just the first frame.\n'none' disables previews."
        },
        {
            "name": "Video Frame Interpolation Method",
            "id": "videoframeinterpolationmethod",
            "description": "How to interpolate frames in the video.\n'RIFE' or 'FILM' are two different decent interpolation model options."
        },
        {
            "name": "Video Frame Interpolation Multiplier",
            "id": "videoframeinterpolationmultiplier",
            "description": "How many frames to interpolate between each frame in the video.\nHigher values are smoother, but make take significant time to save the output, and may have quality artifacts."
        },
        {
            "name": "GLIGEN Model",
            "id": "gligenmodel",
            "description": "Optionally use a GLIGEN model.\nGLIGEN is only compatible with SDv1 at time of writing."
        },
        {
            "name": "Shifted Latent Average Init",
            "id": "shiftedlatentaverageinit",
            "description": "If checked, shifts the empty latent to use a mean-average per-channel latent value (as calculated by Birchlabs).\nIf unchecked, default behavior of zero-init latents are used.\nThis can potentially improve the color range or even general quality on SDv1, SDv2, and SDXL models.\nNote that the effect is very minor."
        },
        {
            "name": "YOLO Model Internal",
            "id": "yolomodelinternal",
            "description": "Parameter for internally tracking YOLOv8 models.\nThis is not for real usage, it is just to expose the list to the UI handler."
        },
        {
            "name": "CLIP-L Model",
            "id": "cliplmodel",
            "description": "Which CLIP-L model to use, for SD3/Flux style 'diffusion_models' folder models."
        },
        {
            "name": "CLIP-G Model",
            "id": "clipgmodel",
            "description": "Which CLIP-G model to use, for SD3 style 'diffusion_models' folder models."
        },
        {
            "name": "T5-XXL Model",
            "id": "txxlmodel",
            "description": "Which T5-XXL model to use, for SD3/Flux style 'diffusion_models' folder models."
        },
        {
            "name": "[AutoWebUI] Sampler",
            "id": "autowebuisampler",
            "description": "Sampler type (for AutoWebUI)"
        }
    ]
}